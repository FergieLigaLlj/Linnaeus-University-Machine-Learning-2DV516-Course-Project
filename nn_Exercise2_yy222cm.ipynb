{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67d522bf",
   "metadata": {},
   "source": [
    "## Exercise 2, Neural networks 'by hand'\n",
    "The exercise is two-parted. First is to fill in the 'missing' code. The overall problem in the first part is to solve the XOR-problem using a neural network.\n",
    "\n",
    "In the second part you should copy your functional code into a new cell, and decrease the initailized weights by a factor of 1/10. What happens? Do you think that the problem is fixable in some way? How? Document your thoughts in a short text either in the notebook (preferred) or separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66bafd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# sigmoid activation\n",
    "def sigmoid(x):\n",
    "    # fill in your code here\n",
    "    return 0\n",
    "\n",
    "# derivative of sigmoid\n",
    "def sigmoid_derivative(x):\n",
    "    # fill in your code here\n",
    "    return 0\n",
    "\n",
    "# cross-entropy loss function\n",
    "def cross_netropy_loss(out_nn, target):\n",
    "    # fill in your code here\n",
    "    return 0\n",
    "\n",
    "# Initialize weights and biases\n",
    "np.random.seed(1)\n",
    "W1 = np.random.randn(2, 2)\n",
    "b1 = np.random.randn(2, 1)\n",
    "W2 = np.random.randn(1, 2)\n",
    "b2 = np.random.randn(1, 1)\n",
    "\n",
    "# xor data\n",
    "X = np.array([[0,0,1,1],[0,1,0,1]])\n",
    "target = np.array([[0, 1, 1, 0]])\n",
    "\n",
    "# forward\n",
    "def forward(X):\n",
    "    # fill in your code here\n",
    "    \n",
    "    # the return should be the output of the network and the\n",
    "    # hidden output which are both used in the backprop\n",
    "    return out, Q1\n",
    "\n",
    "# backpropagation\n",
    "def backprop(X, target, out_nn, Q1):\n",
    "    delta2 = out_nn - target\n",
    "    delta1 = (W2.T@delta2) * sigmoid_derivative(Q1)\n",
    "    dW2 = delta2@Q1.T\n",
    "    dW1 = delta1@X.T\n",
    "    db2 = np.mean(delta2, axis=1, keepdims=True)\n",
    "    db1 = np.mean(delta1, axis=1, keepdims=True)\n",
    "    return dW2, dW1, db2, db1\n",
    "\n",
    "# updating the weights\n",
    "def update(W2, W1, b2, b1, dW2, dW1, db2, db1, alpha):\n",
    "    # fill in your code here\n",
    "    return 0\n",
    "\n",
    "# learning rate\n",
    "alpha = 0.1\n",
    "\n",
    "# print the prediction of the XOR BEFORE training here\n",
    "\n",
    "epochs = 10000\n",
    "for epoch in range(epochs):\n",
    "    # fill in your code here!\n",
    "    # use the above functions to evaluate and update the network\n",
    "    if epoch % 1000 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss}\")\n",
    "\n",
    "# print the prediction of the XOR AFTER training here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
